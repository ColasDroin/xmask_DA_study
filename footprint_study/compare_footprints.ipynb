{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbative footprint study: data creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import shutil\n",
    "from ruamel.yaml import YAML\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import subprocess\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Cern modules\n",
    "import fillingpatterns as fp\n",
    "import xtrack as xt\n",
    "\n",
    "# Improve style\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get machine (built in the script compare_footprints.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collider = xt.Multiline.from_json(\"output/collider_tuned_bb_on.json\")\n",
    "collider.build_trackers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct bbb schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BB schedule\n",
    "fname = \"filling_scheme/8b4e_1972b_1960_1178_1886_224bpi_12inj_800ns_bs200ns.json\"\n",
    "patt = fp.FillingPattern.from_json(fname)\n",
    "\n",
    "# Compute bb schedule\n",
    "patt.compute_beam_beam_schedule(n_lr_per_side=25)\n",
    "bbs_b1 = patt.b1.bb_schedule\n",
    "bbs_b2 = patt.b2.bb_schedule\n",
    "\n",
    "# Get list of bunches\n",
    "bbs_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_bb_elements(collider, bunch_nb, reset_collider=True, also_beam_2=False, print_final_result=False):\n",
    "    # Reset collider\n",
    "    if reset_collider:\n",
    "        for i, x in enumerate(collider.lhcb1.element_names):\n",
    "            if \"bb_lr\" in x or \"bb_ho\" in x:\n",
    "                try:\n",
    "                    collider.lhcb1.vars[x + '_scale_strength'] = collider.lhcb1.vars['beambeam_scale']\n",
    "                    collider.lhcb1.element_refs[x].scale_strength = collider.lhcb1.vars[x + '_scale_strength']\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(f\"Failed to reset {x}\")\n",
    "                    \n",
    "                \n",
    "        for i, x in enumerate(collider.lhcb2.element_names):\n",
    "            if \"bb_lr\" in x or \"bb_ho\" in x:\n",
    "                try:\n",
    "                    collider.lhcb2.vars[x + '_scale_strength'] = collider.lhcb2.vars['beambeam_scale']\n",
    "                    collider.lhcb2.element_refs[x].scale_strength = collider.lhcb2.vars[x + '_scale_strength']\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(f\"Failed to reset {x}\")\n",
    "\n",
    "    # Take care of LR elements\n",
    "    for ip, name_position in zip(\n",
    "        [1, 2, 5, 8],\n",
    "        [\n",
    "            \"Positions in ATLAS/CMS\",\n",
    "            \"Positions in ALICE\",\n",
    "            \"Positions in ATLAS/CMS\",\n",
    "            \"Positions in LHCB\",\n",
    "        ],\n",
    "    ):\n",
    "        # Deactivate elements that shouldn't be here in beam 1\n",
    "        idx_elements_b1 = bbs_b1.loc[bunch_nb][name_position]\n",
    "        for i, x in enumerate(collider.lhcb1.element_names):\n",
    "            # print(collider.lhcb1[x].to_dict())\n",
    "            # First look for bb_elements for current IP\n",
    "            if \"bb_lr.l\" + str(ip) in x or \"bb_lr.r\" + str(ip) in x:\n",
    "                # Then only keep elements corresponding to the current IP\n",
    "                pos = int(x.split(\"_\")[2])\n",
    "                if \"l\" in x.split(\"lr.\")[1]:\n",
    "                    pos = -pos\n",
    "                if pos not in idx_elements_b1:\n",
    "                    collider.lhcb1.element_refs[x].scale_strength = 0\n",
    "\n",
    "        # Same with beam 2\n",
    "        if also_beam_2:\n",
    "            idx_elements_b2 = bbs_b2.loc[bunch_nb][name_position]\n",
    "            for i, x in enumerate(collider.lhcb2.element_names):\n",
    "                if \"bb_lr.l\" + str(ip) in x or \"bb_lr.r\" + str(ip) in x:\n",
    "                    pos = int(x.split(\"_\")[2])\n",
    "                    if \"l\" in x.split(\"lr.\")[1]:\n",
    "                        pos = -pos\n",
    "                    if pos not in idx_elements_b2:\n",
    "                        collider.lhcb2.vars[x + '_scale_strength'] = 0\n",
    "\n",
    "    # Take care of HO elements\n",
    "    for ip, bool_collide in zip(\n",
    "        [1, 2, 5, 8],\n",
    "        [\"collides in ATLAS/CMS\", \"collides in ALICE\", \"collides in ATLAS/CMS\", \"collides in LHCB\"],\n",
    "    ):\n",
    "        collide_b1 = bbs_b1.loc[bunch_nb][bool_collide]\n",
    "\n",
    "        # Deactivate elements that shouldn't be here in beam 1\n",
    "        for i, x in enumerate(collider.lhcb1.element_names):\n",
    "            # First look for bb_elements\n",
    "            if (\n",
    "                \"bb_ho.l\" + str(ip) in x or \"bb_ho.r\" + str(ip) in x or \"bb_ho.c\" + str(ip) in x\n",
    "            ) and not collide_b1:\n",
    "                collider.lhcb1.element_refs[x].scale_strength = 0\n",
    "\n",
    "        # Same with beam 2\n",
    "        if also_beam_2:\n",
    "            collide_b2 = bbs_b2.loc[bunch_nb][bool_collide]\n",
    "            for i, x in enumerate(collider.lhcb2.element_names):\n",
    "                if (\n",
    "                    \"bb_ho.l\" + str(ip) in x or \"bb_ho.r\" + str(ip) in x or \"bb_ho.c\" + str(ip) in x\n",
    "                ) and not collide_b2:\n",
    "                    collider.lhcb2.vars[x + '_scale_strength'] = 0\n",
    "\n",
    "    # Print final result\n",
    "    if print_final_result:\n",
    "        # Beam 1\n",
    "        print(\"Beam 1\")\n",
    "        for i, x in enumerate(collider.lhcb1.element_names):\n",
    "            if \"bb_ho\" in x or \"bb_lr\" in x:\n",
    "                print(x, collider.lhcb1.element_refs[x].scale_strength._value)\n",
    "\n",
    "        # Beam 2\n",
    "        if also_beam_2:\n",
    "            print(\"Beam 2\")\n",
    "            for i, x in enumerate(collider.lhcb2.element_names):\n",
    "                if \"bb_ho\" in x or \"bb_lr\" in x:\n",
    "                    print(x, collider.lhcb2.element_refs[x].scale_strength._value)\n",
    "\n",
    "    # Return collider\n",
    "    return collider"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DA for each bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe for DA\n",
    "path = \"/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/opt_flathv_75_1500_withBB_chroma15_1p4_all_bunches\"\n",
    "df = pd.read_parquet(f\"{path}/da.parquet\")\n",
    "\n",
    "# Round all numbers to 3 decimals\n",
    "df = df.round(3)\n",
    "\n",
    "# Get list of bunches and list of DA\n",
    "l_bunch_nb_from_DA = df[\"bunch_nb\"]\n",
    "l_DA = df[\"normalized amplitude in xy-plane\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coupling correction due to the lattice (```delta_cmr``` and ```delta_cmi``` in pymask) are ignored as they're not very relevant for the coupling study."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get footprint for a selected set bunches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_footprint(collider, bunch_nb, n_turns, perturbative=True, mimic_initial_condition = False):\n",
    "    # Adapt collider for current bunch\n",
    "    collider = fix_bb_elements(\n",
    "        collider, bunch_nb, reset_collider=True, also_beam_2=False, print_final_result=False\n",
    "    )\n",
    "    # Get footprint\n",
    "    if mimic_initial_condition:\n",
    "\n",
    "        # First get initial condition that was built to compute DA\n",
    "        r_max, r_min = 10, 2\n",
    "        radial_list_to_mimic = np.linspace(r_min, r_max, 2 * 16 * (r_max - r_min), endpoint=False)\n",
    "        n_angles = 5\n",
    "        theta_list_to_mimic = np.linspace(0, 90, n_angles + 2)[1:-1]\n",
    "\n",
    "        # Then reproduce this initial condition, knowing that the distributions are generated with\n",
    "        # np.linspace(..., endpoint=True) in the footprint code\n",
    "        fp_polar_xm = collider[\"lhcb1\"].get_footprint(\n",
    "            nemitt_x=2.5e-6,\n",
    "            nemitt_y=2.5e-6,\n",
    "            n_turns=n_turns,\n",
    "            mode = 'polar',\n",
    "            r_range = (radial_list_to_mimic[0],radial_list_to_mimic[-1]),\n",
    "            n_r = len(radial_list_to_mimic),\n",
    "            theta_range = (theta_list_to_mimic[0]/180*np.pi, theta_list_to_mimic[-1]/180*np.pi),\n",
    "            n_theta = len(theta_list_to_mimic),\n",
    "            linear_rescale_on_knobs=[\n",
    "                xt.LinearRescale(knob_name=\"beambeam_scale\", v0=0.0, dv=0.05)\n",
    "            ] if perturbative else None,\n",
    "        )\n",
    "    else:\n",
    "        fp_polar_xm = collider[\"lhcb1\"].get_footprint(\n",
    "            nemitt_x=2.5e-6,\n",
    "            nemitt_y=2.5e-6,\n",
    "            n_turns=n_turns,\n",
    "            linear_rescale_on_knobs=[\n",
    "                xt.LinearRescale(knob_name=\"beambeam_scale\", v0=0.0, dv=0.05)\n",
    "            ] if perturbative else None,\n",
    "        )        \n",
    "\n",
    "    return [fp_polar_xm.qx, fp_polar_xm.qy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bunch nb corresponding to percentile 0, 25, 50, 75, 100 of the DA\n",
    "l_bunch_nb_sampled = []\n",
    "l_DA_sampled = []\n",
    "for p in [0, 25, 50, 75, 100]:\n",
    "    l_bunch_nb_sampled.append(l_bunch_nb_from_DA[l_DA == l_DA.quantile(p / 100)].iloc[0])\n",
    "    l_DA_sampled.append(l_DA.quantile(p / 100))\n",
    "\n",
    "# Get the 4 footprints for each bunch\n",
    "dic_footprints = {bunch_nb:[] for bunch_nb in l_bunch_nb_sampled}\n",
    "n_turns = 2000\n",
    "for bunch_nb in l_bunch_nb_sampled:\n",
    "    dic_footprints[bunch_nb].append(return_footprint(collider, bunch_nb, n_turns=n_turns, perturbative=False, mimic_initial_condition = False))\n",
    "    dic_footprints[bunch_nb].append(return_footprint(collider, bunch_nb, n_turns=n_turns, perturbative=True, mimic_initial_condition = False))\n",
    "    dic_footprints[bunch_nb].append(return_footprint(collider, bunch_nb, n_turns=n_turns, perturbative=False, mimic_initial_condition = True))\n",
    "    dic_footprints[bunch_nb].append(return_footprint(collider, bunch_nb, n_turns=n_turns, perturbative=True, mimic_initial_condition = True))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot sample footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load l_fp\n",
    "with open(\"output_2/l_fp.pkl\", \"rb\") as f:\n",
    "    l_fp = pickle.load(f)[:100]\n",
    "\n",
    "# Load list of bunch numbers\n",
    "with open(\"output_2/l_bunch_nb.pkl\", \"rb\") as f:\n",
    "    l_bunch_nb = pickle.load(f)[:100]\n",
    "\n",
    "# Make a grid of plots for all the footprints\n",
    "n_cols = 10\n",
    "n_rows = int(np.ceil(len(l_fp)/n_cols))\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*2.5, n_rows*2))\n",
    "for i, fp in enumerate(l_fp):\n",
    "    try:\n",
    "        ax = axs[i//n_cols, i%n_cols]\n",
    "        ax.plot(fp[0], fp[1], color=\"C0\")\n",
    "        ax.plot(fp[0].T, fp[1].T, color=\"C0\")\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "        ax.set_xlabel(r\"$\\mathrm{Q_x}$\")\n",
    "        ax.set_ylabel(r\"$\\mathrm{Q_y}$\")\n",
    "        #ax.set_xlim(0, 1)\n",
    "        #ax.set_ylim(0, 1)\n",
    "        ax.grid()\n",
    "        #ax.set_aspect(\"equal\")\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
