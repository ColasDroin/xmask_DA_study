{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbative footprint study: footprints clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard modules\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import hdbscan\n",
    "\n",
    "# Nicer style\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load footprints and plot a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load l_fp\n",
    "with open(\"output/l_fp.pkl\", \"rb\") as f:\n",
    "    l_fp = pickle.load(f)\n",
    "\n",
    "# Load list of bunch numbers\n",
    "with open(\"output/l_bunch_nb.pkl\", \"rb\") as f:\n",
    "    l_bunch_nb = pickle.load(f)\n",
    "\n",
    "# Remove all nan footprints, along with bunch numbers\n",
    "l_bunch_nb = [bunch_nb for i, bunch_nb in enumerate(l_bunch_nb) if not np.isnan(l_fp[i]).any()]\n",
    "l_fp = [fp for fp in l_fp if not np.isnan(fp).any()]\n",
    "\n",
    "\n",
    "# Make a grid of plots for all the footprints\n",
    "sample_nb = 200\n",
    "n_cols = 10\n",
    "n_rows = int(np.ceil(len(l_fp[:sample_nb])/n_cols))\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*2.5, n_rows*2))\n",
    "for i, fp in enumerate(l_fp[:sample_nb]):\n",
    "    try:\n",
    "        ax = axs[i//n_cols, i%n_cols]\n",
    "        ax.plot(fp[0], fp[1], color=\"C0\")\n",
    "        ax.plot(fp[0].T, fp[1].T, color=\"C0\")\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "        ax.set_xlabel(r\"$\\mathrm{Q_x}$\")\n",
    "        ax.set_ylabel(r\"$\\mathrm{Q_y}$\")\n",
    "        #ax.set_aspect(\"equal\")\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "        ax.grid()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers in each figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimensionality with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert matrix samples to a row\n",
    "l_fp_flat = []\n",
    "for i, fp in enumerate(l_fp):\n",
    "    # Process qx and qy separately\n",
    "    fp_x = fp[0].flatten()\n",
    "    fp_y = fp[1].flatten()\n",
    "    l_fp_flat.append([fp_x, fp_y])\n",
    "\n",
    "array_fp_flat = np.array(l_fp_flat)\n",
    "print(array_fp_flat.shape)\n",
    "# apply tsne to the data: rebuild the 2D matrix with only 1 components for each tune dimension\n",
    "pca = PCA(n_components=3)\n",
    "#pca = umap.UMAP(random_state=42)\n",
    "array_fp_flat_qx_ld = pca.fit_transform(array_fp_flat[:,0,:])\n",
    "array_fp_flat_qx_compressed = pca.inverse_transform(array_fp_flat_qx_ld)\n",
    "array_fp_flat_qy_ld = pca.fit_transform(array_fp_flat[:,1,:])\n",
    "array_fp_flat_qy_compressed = pca.inverse_transform(array_fp_flat_qy_ld)\n",
    "\n",
    "# Reshape compressed arrays to original shape\n",
    "array_fp_flat_qx_compressed = np.reshape(array_fp_flat_qx_compressed, (array_fp_flat_qx_compressed.shape[0], l_fp[0][0].shape[0], l_fp[0][0].shape[1]))\n",
    "array_fp_flat_qy_compressed = np.reshape(array_fp_flat_qy_compressed, (array_fp_flat_qy_compressed.shape[0], l_fp[0][1].shape[0], l_fp[0][1].shape[1]))\n",
    "array_fp_flat_compressed = np.array([array_fp_flat_qx_compressed, array_fp_flat_qy_compressed])\n",
    "\n",
    "# switch dimension 0 and 1\n",
    "array_fp_compressed = np.swapaxes(array_fp_flat_compressed, 0, 1)\n",
    "\n",
    "print(array_fp_compressed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grid of plots for all the footprints\n",
    "n_cols = 10\n",
    "n_rows = int(np.ceil(len(l_fp[:sample_nb])/n_cols))\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*2.5, n_rows*2))\n",
    "for i, (fp_compressed, fp_original) in enumerate(zip(array_fp_compressed[:sample_nb], l_fp[:sample_nb])):\n",
    "    try:\n",
    "        ax = axs[i//n_cols, i%n_cols]\n",
    "        ax.plot(fp_compressed[0], fp_compressed[1], color=\"C0\")\n",
    "        ax.plot(fp_compressed[0].T, fp_compressed[1].T, color=\"C0\")\n",
    "        ax.plot(fp_original[0], fp_original[1], color=\"C1\", alpha = 0.5)\n",
    "        ax.plot(fp_original[0].T, fp_original[1].T, color=\"C1\", alpha = 0.5)\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "        ax.set_xlabel(r\"$\\mathrm{Q_x}$\")\n",
    "        ax.set_ylabel(r\"$\\mathrm{Q_y}$\")\n",
    "        #ax.set_aspect(\"equal\")\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "        ax.grid()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster the resulting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "# Get 4D data\n",
    "array_fp_ld = np.hstack([array_fp_flat_qx_ld, array_fp_flat_qy_ld])\n",
    "\n",
    "# Apply HDBSCAN\n",
    "#clusterer = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=10).fit(array_fp_ld)\n",
    "#\n",
    "bandwidth = estimate_bandwidth(array_fp_ld, quantile=0.12, n_samples=len(array_fp_ld))\n",
    "clusterer = MeanShift(bandwidth=bandwidth, bin_seeding=True).fit(array_fp_ld)\n",
    "clusterer.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot initial data according to labels\n",
    "n_cols = 10\n",
    "n_rows = int(np.ceil(len(l_fp[:sample_nb])/n_cols))\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*2.5, n_rows*2))\n",
    "for i, fp in enumerate(l_fp[:sample_nb]):\n",
    "    try:\n",
    "        ax = axs[i//n_cols, i%n_cols]\n",
    "        ax.plot(fp[0], fp[1], color=\"C\" + str(clusterer.labels_[i]))\n",
    "        ax.plot(fp[0].T, fp[1].T, color=\"C\" + str(clusterer.labels_[i]))\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "        ax.set_xlabel(r\"$\\mathrm{Q_x}$\")\n",
    "        ax.set_ylabel(r\"$\\mathrm{Q_y}$\")\n",
    "        #ax.set_aspect(\"equal\")\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "        ax.grid()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
