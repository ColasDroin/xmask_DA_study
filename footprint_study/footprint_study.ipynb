{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbative footprint study: data creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import shutil\n",
    "from ruamel.yaml import YAML\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import subprocess\n",
    "import time\n",
    "#from multiprocessing import Pool\n",
    "#from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "# Cern modules\n",
    "import fillingpatterns as fp\n",
    "import xtrack as xt\n",
    "\n",
    "# Improve style\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a machine with xmask from the appropriate configuration file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First create a proper configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy default configuration file for xmask, and target configuration file for pymask\n",
    "shutil.copyfile(\"../modules/xmask/examples/hllhc15_collision/config.yaml\", \"config_xm.yaml\")\n",
    "shutil.copyfile(\n",
    "    \"/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/opt_flathv_75_1500_withBB_chroma15_1p4_all_bunches/madx_001/config.yaml\",\n",
    "    \"config_pm.yaml\",\n",
    ")\n",
    "\n",
    "\n",
    "# Read and mutate xmask config file\n",
    "with open(\"config_xm.yaml\", \"r\") as fid:\n",
    "    config_xm_str = fid.read()\n",
    "\n",
    "with open(\"config_pm.yaml\", \"r\") as fid:\n",
    "    config_pm_str = fid.read()\n",
    "\n",
    "yaml = YAML()\n",
    "config_pm = yaml.load(config_pm_str)\n",
    "config_xm = yaml.load(config_xm_str)\n",
    "\n",
    "# Hardcode optics configuration files as they can't be ported directly\n",
    "config_xm[\"config_mad\"][\"links\"][\"acc-models-lhc\"] = \"/afs/cern.ch/eng/lhc/optics/HLLHCV1.5\"\n",
    "config_xm[\"config_mad\"][\"optics_file\"] = \"acc-models-lhc/flatcc/opt_flathv_75_180_1500_thin.madx\"\n",
    "config_xm[\"config_knobs_and_tuning\"][\"closed_orbit_correction\"][\n",
    "    \"lhcb1\"\n",
    "] = \"../modules/tools/corr_co_lhcb1.json\"\n",
    "config_xm[\"config_knobs_and_tuning\"][\"closed_orbit_correction\"][\n",
    "    \"lhcb2\"\n",
    "] = \"../modules/tools/corr_co_lhcb2.json\"\n",
    "\n",
    "# Mutate optics and check config\n",
    "config_xm[\"config_mad\"][\"enable_imperfections\"] = config_pm[\"enable_imperfections\"]\n",
    "config_xm[\"config_mad\"][\"enable_knob_synthesis\"] = config_pm[\"enable_knob_synthesis\"]\n",
    "config_xm[\"config_mad\"][\"ver_hllhc_optics\"] = float(config_pm[\"optics_version\"])\n",
    "config_xm[\"config_mad\"][\"pars_for_imperfections\"] = config_pm[\"pars_for_imperfections\"]\n",
    "\n",
    "# Mutate beam config\n",
    "config_xm[\"config_mad\"][\"beam_config\"][\"lhcb1\"][\"beam_energy_tot\"] = config_pm[\"beam_energy_tot\"]\n",
    "config_xm[\"config_mad\"][\"beam_config\"][\"lhcb2\"][\"beam_energy_tot\"] = config_pm[\"beam_energy_tot\"]\n",
    "\n",
    "# Mutate beambeam parameters\n",
    "config_xm[\"config_beambeam\"][\"nemitt_x\"] = config_pm[\"beam_norm_emit_x\"] * 1e-6\n",
    "config_xm[\"config_beambeam\"][\"nemitt_y\"] = config_pm[\"beam_norm_emit_y\"] * 1e-6\n",
    "config_xm[\"config_beambeam\"][\"sigma_z\"] = config_pm[\"beam_sigt\"]\n",
    "config_xm[\"config_beambeam\"][\"num_particles_per_bunch\"] = config_pm[\"beam_npart\"]\n",
    "config_xm[\"config_beambeam\"][\"num_particles_per_bunch\"] = config_pm[\"beam_npart\"]\n",
    "for i, ip in enumerate([\"ip1\", \"ip2\", \"ip5\", \"ip8\"]):\n",
    "    config_xm[\"config_beambeam\"][\"num_long_range_encounters_per_side\"][ip] = config_pm[\n",
    "        \"beambeam_config\"\n",
    "    ][\"numberOfLRPerIRSide\"][i]\n",
    "config_xm[\"config_beambeam\"][\"num_slices_head_on\"] = config_pm[\"beambeam_config\"][\n",
    "    \"numberOfHOSlices\"\n",
    "]\n",
    "config_xm[\"config_beambeam\"][\"bunch_spacing_buckets\"] = config_pm[\"beambeam_config\"][\n",
    "    \"bunch_spacing_buckets\"\n",
    "]\n",
    "\n",
    "# Mutate tunes and chromaticities (assume same for both beams, since not settable in pymask)\n",
    "config_xm[\"config_knobs_and_tuning\"][\"qx\"][\"lhcb1\"] = config_pm[\"qx0\"]\n",
    "config_xm[\"config_knobs_and_tuning\"][\"qx\"][\"lhcb2\"] = config_pm[\"qx0\"]\n",
    "config_xm[\"config_knobs_and_tuning\"][\"qy\"][\"lhcb1\"] = config_pm[\"qy0\"]\n",
    "config_xm[\"config_knobs_and_tuning\"][\"qy\"][\"lhcb2\"] = config_pm[\"qy0\"]\n",
    "config_xm[\"config_knobs_and_tuning\"][\"dqx\"][\"lhcb1\"] = config_pm[\"chromaticity_x\"]\n",
    "config_xm[\"config_knobs_and_tuning\"][\"dqx\"][\"lhcb2\"] = config_pm[\"chromaticity_x\"]\n",
    "config_xm[\"config_knobs_and_tuning\"][\"dqy\"][\"lhcb1\"] = config_pm[\"chromaticity_y\"]\n",
    "config_xm[\"config_knobs_and_tuning\"][\"dqy\"][\"lhcb2\"] = config_pm[\"chromaticity_y\"]\n",
    "\n",
    "# Mutate knobs\n",
    "for knob in config_pm[\"knob_settings\"]:\n",
    "    if knob in config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"]:\n",
    "        config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][knob] = config_pm[\"knob_settings\"][\n",
    "            knob\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"Knob {knob} not found in xmask config file. Beind added now.\")\n",
    "        config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][knob] = config_pm[\"knob_settings\"][\n",
    "            knob\n",
    "        ]\n",
    "\n",
    "# Mutate RF voltage and octupole current\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"vrf400\"] = config_pm[\"vrf_total\"]\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"i_oct_b1\"] = config_pm[\"oct_current\"]\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"i_oct_b2\"] = config_pm[\"oct_current\"]\n",
    "\n",
    "\n",
    "# Artificially implement end of luminosity levelling\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"on_sep8\"] = 0.0\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"on_sep8h\"] = -0.01745641501719127\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"on_sep8v\"] = 0.01371863979152592\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"on_x8\"] = 0.0\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"on_x8h\"] = 0.0\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"on_x8v\"] = 170.0\n",
    "config_xm[\"config_knobs_and_tuning\"][\"knob_settings\"][\"on_sep2\"] = 0.1443593672910653\n",
    "\n",
    "\n",
    "# ! WARNING. AT THIS POINT:\n",
    "# ! - Coupling is missing\n",
    "# ! - bunch-by-bunch and filling schemes are missing\n",
    "\n",
    "\n",
    "# Write config file\n",
    "with open(\"config_xm.yaml\", \"w\") as fid:\n",
    "    yaml.dump(config_xm, fid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD = False\n",
    "if REBUILD:\n",
    "    os.system(\"python build_machine.py\")\n",
    "collider = xt.Multiline.from_json(\"output/collider_tuned_bb_on.json\")\n",
    "collider.build_trackers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct bbb schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BB schedule\n",
    "fname = \"filling_scheme/8b4e_1972b_1960_1178_1886_224bpi_12inj_800ns_bs200ns.json\"\n",
    "patt = fp.FillingPattern.from_json(fname)\n",
    "\n",
    "# Compute bb schedule\n",
    "patt.compute_beam_beam_schedule(n_lr_per_side=25)\n",
    "bbs_b1 = patt.b1.bb_schedule\n",
    "bbs_b2 = patt.b2.bb_schedule\n",
    "\n",
    "# Get list of bunches\n",
    "bbs_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_bb_elements(collider, bunch_nb, reset_collider=True, also_beam_2=False, print_final_result=False):\n",
    "    # Reset collider\n",
    "    if reset_collider:\n",
    "        for i, x in enumerate(collider.lhcb1.element_names):\n",
    "            if \"bb_lr\" in x or \"bb_ho\" in x:\n",
    "                try:\n",
    "                    collider.lhcb1.vars[x + '_scale_strength'] = collider.lhcb1.vars['beambeam_scale']\n",
    "                    collider.lhcb1.element_refs[x].scale_strength = collider.lhcb1.vars[x + '_scale_strength']\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(f\"Failed to reset {x}\")\n",
    "                    \n",
    "                \n",
    "        for i, x in enumerate(collider.lhcb2.element_names):\n",
    "            if \"bb_lr\" in x or \"bb_ho\" in x:\n",
    "                try:\n",
    "                    collider.lhcb2.vars[x + '_scale_strength'] = collider.lhcb2.vars['beambeam_scale']\n",
    "                    collider.lhcb2.element_refs[x].scale_strength = collider.lhcb2.vars[x + '_scale_strength']\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(f\"Failed to reset {x}\")\n",
    "\n",
    "    # Take care of LR elements\n",
    "    for ip, name_position in zip(\n",
    "        [1, 2, 5, 8],\n",
    "        [\n",
    "            \"Positions in ATLAS/CMS\",\n",
    "            \"Positions in ALICE\",\n",
    "            \"Positions in ATLAS/CMS\",\n",
    "            \"Positions in LHCB\",\n",
    "        ],\n",
    "    ):\n",
    "        # Deactivate elements that shouldn't be here in beam 1\n",
    "        idx_elements_b1 = bbs_b1.loc[bunch_nb][name_position]\n",
    "        for i, x in enumerate(collider.lhcb1.element_names):\n",
    "            # print(collider.lhcb1[x].to_dict())\n",
    "            # First look for bb_elements for current IP\n",
    "            if \"bb_lr.l\" + str(ip) in x or \"bb_lr.r\" + str(ip) in x:\n",
    "                # Then only keep elements corresponding to the current IP\n",
    "                pos = int(x.split(\"_\")[2])\n",
    "                if \"l\" in x.split(\"lr.\")[1]:\n",
    "                    pos = -pos\n",
    "                if pos not in idx_elements_b1:\n",
    "                    collider.lhcb1.element_refs[x].scale_strength = 0\n",
    "\n",
    "        # Same with beam 2\n",
    "        if also_beam_2:\n",
    "            idx_elements_b2 = bbs_b2.loc[bunch_nb][name_position]\n",
    "            for i, x in enumerate(collider.lhcb2.element_names):\n",
    "                if \"bb_lr.l\" + str(ip) in x or \"bb_lr.r\" + str(ip) in x:\n",
    "                    pos = int(x.split(\"_\")[2])\n",
    "                    if \"l\" in x.split(\"lr.\")[1]:\n",
    "                        pos = -pos\n",
    "                    if pos not in idx_elements_b2:\n",
    "                        collider.lhcb2.vars[x + '_scale_strength'] = 0\n",
    "\n",
    "    # Take care of HO elements\n",
    "    for ip, bool_collide in zip(\n",
    "        [1, 2, 5, 8],\n",
    "        [\"collides in ATLAS/CMS\", \"collides in ALICE\", \"collides in ATLAS/CMS\", \"collides in LHCB\"],\n",
    "    ):\n",
    "        collide_b1 = bbs_b1.loc[bunch_nb][bool_collide]\n",
    "\n",
    "        # Deactivate elements that shouldn't be here in beam 1\n",
    "        for i, x in enumerate(collider.lhcb1.element_names):\n",
    "            # First look for bb_elements\n",
    "            if (\n",
    "                \"bb_ho.l\" + str(ip) in x or \"bb_ho.r\" + str(ip) in x or \"bb_ho.c\" + str(ip) in x\n",
    "            ) and not collide_b1:\n",
    "                collider.lhcb1.element_refs[x].scale_strength = 0\n",
    "\n",
    "        # Same with beam 2\n",
    "        if also_beam_2:\n",
    "            collide_b2 = bbs_b2.loc[bunch_nb][bool_collide]\n",
    "            for i, x in enumerate(collider.lhcb2.element_names):\n",
    "                if (\n",
    "                    \"bb_ho.l\" + str(ip) in x or \"bb_ho.r\" + str(ip) in x or \"bb_ho.c\" + str(ip) in x\n",
    "                ) and not collide_b2:\n",
    "                    collider.lhcb2.vars[x + '_scale_strength'] = 0\n",
    "\n",
    "    # Print final result\n",
    "    if print_final_result:\n",
    "        # Beam 1\n",
    "        print(\"Beam 1\")\n",
    "        for i, x in enumerate(collider.lhcb1.element_names):\n",
    "            if \"bb_ho\" in x or \"bb_lr\" in x:\n",
    "                print(x, collider.lhcb1.element_refs[x].scale_strength._value)\n",
    "\n",
    "        # Beam 2\n",
    "        if also_beam_2:\n",
    "            print(\"Beam 2\")\n",
    "            for i, x in enumerate(collider.lhcb2.element_names):\n",
    "                if \"bb_ho\" in x or \"bb_lr\" in x:\n",
    "                    print(x, collider.lhcb2.element_refs[x].scale_strength._value)\n",
    "\n",
    "    # Return collider\n",
    "    return collider"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot footprint for a given bunch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coupling correction due to the lattice (```delta_cmr``` and ```delta_cmi``` in pymask) are ignored as they're not very relevant for the coupling study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evolution_with_nturns = False\n",
    "if plot_evolution_with_nturns:\n",
    "    bunch_nb = 23\n",
    "    collider = fix_bb_elements(\n",
    "        collider, bunch_nb, reset_collider=True, also_beam_2=False, print_final_result=False\n",
    "    )\n",
    "\n",
    "    print('OK SO FAR')\n",
    "    for n_turns in [100, 500, 1000, 5000, 20000]:\n",
    "        # Plot footprint\n",
    "        fp_polar_xm = collider[\"lhcb1\"].get_footprint(\n",
    "            nemitt_x=2.5e-6,\n",
    "            nemitt_y=2.5e-6,\n",
    "            n_turns=n_turns,\n",
    "            linear_rescale_on_knobs=[\n",
    "                xt.LinearRescale(knob_name=\"beambeam_scale\", v0=0.0, dv=0.1 / 2)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        fp_polar_xm.plot(ax=ax)\n",
    "        ax.set_title(f\"Footprint for {n_turns} turns\")\n",
    "        #plt.show()\n",
    "        plt.savefig(f\"output/footprint_xm_{n_turns}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_result_without_coupling = False\n",
    "# Check result without coupling\n",
    "if check_result_without_coupling:\n",
    "    # Save values before changing anything\n",
    "    c_minus_re_b1_before_correction = collider.vars[\"c_minus_re_b1\"]._value\n",
    "    c_minus_re_b2_before_correction = collider.vars[\"c_minus_re_b2\"]._value\n",
    "    c_minus_im_b1_before_correction = collider.vars[\"c_minus_im_b1\"]._value\n",
    "    c_minus_im_b2_before_correction = collider.vars[\"c_minus_im_b2\"]._value\n",
    "\n",
    "    # Set all couplings to zero\n",
    "    collider.vars[\"c_minus_re_b1\"] = 0\n",
    "    collider.vars[\"c_minus_im_b1\"] = 0\n",
    "    collider.vars[\"c_minus_re_b2\"] = 0\n",
    "    collider.vars[\"c_minus_im_b2\"] = 0\n",
    "\n",
    "    # Twiss just to be safe\n",
    "    collider[\"lhcb1\"].twiss()\n",
    "    collider[\"lhcb2\"].twiss()\n",
    "\n",
    "    # Plot footprint\n",
    "    fp_polar_xm = collider[\"lhcb1\"].get_footprint(\n",
    "        nemitt_x=2.5e-6,\n",
    "        nemitt_y=2.5e-6,\n",
    "        n_turns=2000,\n",
    "        linear_rescale_on_knobs=[xt.LinearRescale(knob_name=\"beambeam_scale\", v0=0.0, dv=0.1 / 2)],\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    fp_polar_xm.plot(ax=ax, label=\"no rescale bb\")\n",
    "    plt.show()\n",
    "\n",
    "    # Reset values\n",
    "    collider.vars[\"c_minus_re_b1\"] = c_minus_re_b1_before_correction\n",
    "    collider.vars[\"c_minus_im_b1\"] = c_minus_im_b1_before_correction\n",
    "    collider.vars[\"c_minus_re_b2\"] = c_minus_re_b2_before_correction\n",
    "    collider.vars[\"c_minus_im_b2\"] = c_minus_im_b2_before_correction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get footprint for all bunches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_footprint(collider, bunch_nb, n_turns):\n",
    "    # Adapt collider for current bunch\n",
    "    collider = fix_bb_elements(\n",
    "        collider, bunch_nb, reset_collider=True, also_beam_2=False, print_final_result=False\n",
    "    )\n",
    "    # Get footprint\n",
    "    fp_polar_xm = collider[\"lhcb1\"].get_footprint(\n",
    "        nemitt_x=2.5e-6,\n",
    "        nemitt_y=2.5e-6,\n",
    "        n_turns=n_turns,\n",
    "        linear_rescale_on_knobs=[\n",
    "            xt.LinearRescale(knob_name=\"beambeam_scale\", v0=0.0, dv=0.05)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return [fp_polar_xm.qx, fp_polar_xm.qy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_footprint_in_parallel_scripts(collider, l_bunch_nb, n_turns):\n",
    "    wd = os.getcwd()\n",
    "\n",
    "    # Build a temporary folder for each bunch number\n",
    "    for bunch_nb in l_bunch_nb:\n",
    "        # Ensure you're in workind directory\n",
    "        os.chdir(wd)\n",
    "\n",
    "        # Create folder\n",
    "        folder_name = f\"output/{bunch_nb}\"\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "\n",
    "        # Adapt collider\n",
    "        collider = fix_bb_elements(\n",
    "            collider, bunch_nb, reset_collider=True, also_beam_2=False, print_final_result=False\n",
    "        )\n",
    "\n",
    "        # Save collider as json\n",
    "        collider.to_json(f\"{folder_name}/collider_tuned_bb_on.json\")\n",
    "\n",
    "        # Build a file containing a python script in which I create collider and compute footprint\n",
    "        with open(f\"{folder_name}/footprint.py\", \"w\") as f:\n",
    "            f.write(f\"\"\"\n",
    "import pickle\n",
    "import xtrack as xt\n",
    "\n",
    "# Load collider\n",
    "collider = xt.Multiline.from_json(f\"collider_tuned_bb_on.json\")\n",
    "collider.build_trackers()\n",
    "\n",
    "# Compute footprint\n",
    "fp_polar_xm = collider[\"lhcb1\"].get_footprint(\n",
    "    nemitt_x=2.5e-6,\n",
    "    nemitt_y=2.5e-6,\n",
    "    n_turns={n_turns},\n",
    "    linear_rescale_on_knobs=[\n",
    "        xt.LinearRescale(knob_name=\"beambeam_scale\", v0=0.0, dv=0.05)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Save footprint\n",
    "with open(f\"fp_polar_xm.pkl\", \"wb\") as f:\n",
    "    pickle.dump([fp_polar_xm.qx, fp_polar_xm.qy], f)\n",
    "            \"\"\")\n",
    "        \n",
    "        # Move to the folder\n",
    "        os.chdir(f\"{folder_name}/\")\n",
    "\n",
    "        # Run script using subprocess\n",
    "        subprocess.run(f\"python footprint.py &\", shell=True)\n",
    "\n",
    "    # Move back to working directory\n",
    "    os.chdir(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_bunch_nb =  list(bbs_b1.index)\n",
    "n_turns = 2000\n",
    "\n",
    "# Multiprocessing or multithreading in Python doesn't seem to work :'(\n",
    "do_multiprocessing_in_notebook = False\n",
    "if do_multiprocessing_in_notebook:\n",
    "    pool = Pool(4)\n",
    "    l_fp = [x for x in pool.starmap(return_footprint, [ (xt.Multiline.from_dict(collider.to_dict()), bunch_nb, n_turns) for bunch_nb in l_bunch_nb[:2]])]\n",
    "\n",
    "# So I do multiprocessing through scripts\n",
    "do_multiprocessing_in_script = True\n",
    "if do_multiprocessing_in_script:\n",
    "    size_series = 80\n",
    "    for series in range(0, len(l_bunch_nb), size_series):\n",
    "        print(f\"Running series {series} to {series+size_series}\")\n",
    "        run_footprint_in_parallel_scripts(collider, l_bunch_nb[series:series+size_series], n_turns)\n",
    "        # Check every 30 seconds if the last job of the series is done\n",
    "        while not os.path.exists(f\"output/{l_bunch_nb[series+size_series-1]}/fp_polar_xm.pkl\"):\n",
    "            time.sleep(30)\n",
    "\n",
    "\n",
    "\n",
    "# Running jobs in series is way too slow   \n",
    "else:\n",
    "    l_fp = []\n",
    "    for bunch_nb in l_bunch_nb:\n",
    "        l_fp.append(return_footprint(collider, bunch_nb, n_turns))\n",
    "\n",
    "    # Save l_fp\n",
    "    with open(\"output/l_fp.pkl\", \"wb\") as f:\n",
    "        pickle.dump(l_fp, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_multiprocessing_in_script:\n",
    "    # Rebuild l_fp\n",
    "    l_fp = []\n",
    "    for bunch_nb in l_bunch_nb:\n",
    "        try:\n",
    "            with open(f\"output/{bunch_nb}/fp_polar_xm.pkl\", \"rb\") as f:\n",
    "                l_fp.append(pickle.load(f))\n",
    "        except Exception as e:\n",
    "            print(f\"Error with bunch_nb {bunch_nb}: {e}\")\n",
    "            l_fp.append([np.nan, np.nan])\n",
    "    \n",
    "    # Save l_fp\n",
    "    with open(\"output/l_fp.pkl\", \"wb\") as f:\n",
    "        pickle.dump(l_fp, f)\n",
    "\n",
    "    # Save list of bunch numbers\n",
    "    with open(\"output/l_bunch_nb.pkl\", \"wb\") as f:\n",
    "        pickle.dump(l_bunch_nb, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot sample footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load l_fp\n",
    "with open(\"output/l_fp.pkl\", \"rb\") as f:\n",
    "    l_fp = pickle.load(f)[:100]\n",
    "\n",
    "# Load list of bunch numbers\n",
    "with open(\"output/l_bunch_nb.pkl\", \"rb\") as f:\n",
    "    l_bunch_nb = pickle.load(f)[:100]\n",
    "\n",
    "# Make a grid of plots for all the footprints\n",
    "n_cols = 10\n",
    "n_rows = int(np.ceil(len(l_fp)/n_cols))\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*2.5, n_rows*2))\n",
    "for i, fp in enumerate(l_fp):\n",
    "    try:\n",
    "        ax = axs[i//n_cols, i%n_cols]\n",
    "        ax.plot(fp[0], fp[1], color=\"C0\")\n",
    "        ax.plot(fp[0].T, fp[1].T, color=\"C0\")\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "        ax.set_xlabel(r\"$\\mathrm{Q_x}$\")\n",
    "        ax.set_ylabel(r\"$\\mathrm{Q_y}$\")\n",
    "        #ax.set_xlim(0, 1)\n",
    "        #ax.set_ylim(0, 1)\n",
    "        ax.grid()\n",
    "        #ax.set_aspect(\"equal\")\n",
    "        ax.set_title(f\"Bunch {l_bunch_nb[i]}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
